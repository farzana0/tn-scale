Device: cuda
Prefix: poly5_D100
Batch size: 2000, Num epochs: 600
Bond dim: 80, LR: 0.001, L2: 0.0

Base points: N_base_total=100, using N_base=100, D=100
Using N_T_NODES=6 Chebyshev nodes in t for path augmentation.
Feature map: poly5_x_then_one

Path-augmented dataset size (h + g_i paths): 60600 points = (1 + D)*N_base*N_T_NODES
Feature-space dim D_aug=200

Training MPS on path-augmented regression
N_train=60600, D_aug=200, bond_dim=80
LR=0.001, L2=0.0
Early stopping patience=50, LR patience=5, factor=0.8

### Epoch 001 ###
Train MSE (normalized y): 7.180824e+09 | R²: -0.000762
Avg grad norm: 2007185133715.6912 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 0/50
Runtime so far: 19 sec

### Epoch 002 ###
Train MSE (normalized y): 4.011152e+00 | R²: -0.138974
Avg grad norm: 1068.4584 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 1/50
Runtime so far: 37 sec

### Epoch 003 ###
Train MSE (normalized y): 1.367172e+01 | R²: -0.130277
Avg grad norm: 4164.2871 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 2/50
Runtime so far: 56 sec

### Epoch 004 ###
Train MSE (normalized y): 2.259811e+02 | R²: -0.039504
Avg grad norm: 60758.4923 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 3/50
Runtime so far: 75 sec

### Epoch 005 ###
Train MSE (normalized y): 1.212220e+01 | R²: -1.970471
Avg grad norm: 2726.9636 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 4/50
Runtime so far: 94 sec

### Epoch 006 ###
Train MSE (normalized y): 9.617710e+00 | R²: -0.159754
Avg grad norm: 1511.6483 | LR: 1.00e-03
Best R²: -0.000762 (epoch 1) | No improve: 5/50
Runtime so far: 113 sec

Epoch 00007: reducing learning rate of group 0 to 8.0000e-04.
### Epoch 007 ###
Train MSE (normalized y): 8.516516e+00 | R²: -67.176445
Avg grad norm: 1447.3529 | LR: 8.00e-04
Best R²: -0.000762 (epoch 1) | No improve: 6/50
Runtime so far: 132 sec

### Epoch 008 ###
Train MSE (normalized y): 8.784798e+02 | R²: -3.140066
Avg grad norm: 140147.4103 | LR: 8.00e-04
Best R²: -0.000762 (epoch 1) | No improve: 7/50
Runtime so far: 151 sec

### Epoch 009 ###
Train MSE (normalized y): 3.328680e+00 | R²: -4753.244629
Avg grad norm: 440.8974 | LR: 8.00e-04
Best R²: -0.000762 (epoch 1) | No improve: 8/50
Runtime so far: 170 sec

### Epoch 010 ###
Train MSE (normalized y): 1.178688e+00 | R²: -10.410920
Avg grad norm: 61.0207 | LR: 8.00e-04
Best R²: -0.000762 (epoch 1) | No improve: 9/50
Runtime so far: 189 sec

### Epoch 011 ###
Train MSE (normalized y): 1.330638e+01 | R²: 0.000047
Avg grad norm: 1794.3021 | LR: 8.00e-04
Best R²: 0.000047 (epoch 11) | No improve: 0/50
Runtime so far: 208 sec

### Epoch 012 ###
Train MSE (normalized y): 9.999609e-01 | R²: 0.023724
Avg grad norm: 0.0350 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 0/50
Runtime so far: 227 sec

### Epoch 013 ###
Train MSE (normalized y): 1.002447e+00 | R²: 0.014847
Avg grad norm: 0.8193 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 1/50
Runtime so far: 246 sec

### Epoch 014 ###
Train MSE (normalized y): 1.888478e+00 | R²: -9298.276367
Avg grad norm: 141.6055 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 2/50
Runtime so far: 265 sec

### Epoch 015 ###
Train MSE (normalized y): 2.336275e+00 | R²: 0.000017
Avg grad norm: 270.7749 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 3/50
Runtime so far: 284 sec

### Epoch 016 ###
Train MSE (normalized y): 9.999764e-01 | R²: 0.000056
Avg grad norm: 0.0068 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 4/50
Runtime so far: 303 sec

### Epoch 017 ###
Train MSE (normalized y): 9.982736e-01 | R²: -10.976138
Avg grad norm: 0.0766 | LR: 8.00e-04
Best R²: 0.023724 (epoch 12) | No improve: 5/50
Runtime so far: 322 sec

Epoch 00018: reducing learning rate of group 0 to 6.4000e-04.
### Epoch 018 ###
Train MSE (normalized y): 1.954499e+01 | R²: -37.708118
Avg grad norm: 4610.0299 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 6/50
Runtime so far: 341 sec

### Epoch 019 ###
Train MSE (normalized y): 1.668733e+00 | R²: -164.301437
Avg grad norm: 169.7771 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 7/50
Runtime so far: 360 sec

### Epoch 020 ###
Train MSE (normalized y): 1.026708e+00 | R²: -3583482.750000
Avg grad norm: 8.6957 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 8/50
Runtime so far: 379 sec

### Epoch 021 ###
Train MSE (normalized y): 4.893394e+01 | R²: -11.273314
Avg grad norm: 9530.0993 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 9/50
Runtime so far: 398 sec

### Epoch 022 ###
Train MSE (normalized y): 7.643387e+03 | R²: -0.017811
Avg grad norm: 966129.2849 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 10/50
Runtime so far: 417 sec

### Epoch 023 ###
Train MSE (normalized y): 9.999836e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 6.40e-04
Best R²: 0.023724 (epoch 12) | No improve: 11/50
Runtime so far: 436 sec

Epoch 00024: reducing learning rate of group 0 to 5.1200e-04.
### Epoch 024 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 12/50
Runtime so far: 455 sec

### Epoch 025 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 13/50
Runtime so far: 474 sec

### Epoch 026 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 14/50
Runtime so far: 493 sec

### Epoch 027 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 15/50
Runtime so far: 512 sec

### Epoch 028 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 16/50
Runtime so far: 531 sec

### Epoch 029 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 5.12e-04
Best R²: 0.023724 (epoch 12) | No improve: 17/50
Runtime so far: 550 sec

Epoch 00030: reducing learning rate of group 0 to 4.0960e-04.
### Epoch 030 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 18/50
Runtime so far: 569 sec

### Epoch 031 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 19/50
Runtime so far: 588 sec

### Epoch 032 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 20/50
Runtime so far: 607 sec

### Epoch 033 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 21/50
Runtime so far: 626 sec

### Epoch 034 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 22/50
Runtime so far: 645 sec

### Epoch 035 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 4.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 23/50
Runtime so far: 664 sec

Epoch 00036: reducing learning rate of group 0 to 3.2768e-04.
### Epoch 036 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 24/50
Runtime so far: 683 sec

### Epoch 037 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 25/50
Runtime so far: 702 sec

### Epoch 038 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 26/50
Runtime so far: 721 sec

### Epoch 039 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 27/50
Runtime so far: 740 sec

### Epoch 040 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 28/50
Runtime so far: 759 sec

### Epoch 041 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 3.28e-04
Best R²: 0.023724 (epoch 12) | No improve: 29/50
Runtime so far: 778 sec

Epoch 00042: reducing learning rate of group 0 to 2.6214e-04.
### Epoch 042 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 30/50
Runtime so far: 797 sec

### Epoch 043 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 31/50
Runtime so far: 816 sec

### Epoch 044 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 32/50
Runtime so far: 835 sec

### Epoch 045 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 33/50
Runtime so far: 854 sec

### Epoch 046 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 34/50
Runtime so far: 873 sec

### Epoch 047 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.62e-04
Best R²: 0.023724 (epoch 12) | No improve: 35/50
Runtime so far: 892 sec

Epoch 00048: reducing learning rate of group 0 to 2.0972e-04.
### Epoch 048 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 36/50
Runtime so far: 910 sec

### Epoch 049 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 37/50
Runtime so far: 929 sec

### Epoch 050 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 38/50
Runtime so far: 948 sec

### Epoch 051 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 39/50
Runtime so far: 967 sec

### Epoch 052 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 40/50
Runtime so far: 986 sec

### Epoch 053 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 2.10e-04
Best R²: 0.023724 (epoch 12) | No improve: 41/50
Runtime so far: 1005 sec

Epoch 00054: reducing learning rate of group 0 to 1.6777e-04.
### Epoch 054 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 42/50
Runtime so far: 1024 sec

### Epoch 055 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 43/50
Runtime so far: 1043 sec

### Epoch 056 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 44/50
Runtime so far: 1062 sec

### Epoch 057 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 45/50
Runtime so far: 1081 sec

### Epoch 058 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 46/50
Runtime so far: 1100 sec

### Epoch 059 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.68e-04
Best R²: 0.023724 (epoch 12) | No improve: 47/50
Runtime so far: 1119 sec

Epoch 00060: reducing learning rate of group 0 to 1.3422e-04.
### Epoch 060 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.34e-04
Best R²: 0.023724 (epoch 12) | No improve: 48/50
Runtime so far: 1138 sec

### Epoch 061 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.34e-04
Best R²: 0.023724 (epoch 12) | No improve: 49/50
Runtime so far: 1157 sec

### Epoch 062 ###
Train MSE (normalized y): 9.999835e-01 | R²: 0.000017
Avg grad norm: 0.0000 | LR: 1.34e-04
Best R²: 0.023724 (epoch 12) | No improve: 50/50
Runtime so far: 1176 sec


⚠️ Early stopping at epoch 62. Restoring best model from epoch 12 (R²=0.023724).
Saved TN-SHAP targets to poly5_D100_tnshap_targets.pt
Saved trained MPS to poly5_D100_mps.pt
Done.
