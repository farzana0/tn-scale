#!/usr/bin/env python3
"""
train_mps.py

Train an MPS on the Chebyshev data generated by poly_teacher.py.
We append a leading 1 to each input vector so MPS can represent a bias term.

Run (after generating data with poly_teacher.py):
    python poly_teacher.py           # once
    python train_mps.py              # trains and saves MPS
"""

import time
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader

from torchmps import MPS
from poly_teacher import load_teacher, load_data

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -----------------------
# Config
# -----------------------
PREFIX = "poly"       # must match --prefix in poly_teacher.py
BATCH_SIZE = 256
NUM_EPOCHS = 50
BOND_DIM = 20
LEARN_RATE = 1e-3
L2_REG = 0.0


def r2_score(y_true, y_pred) -> float:
    y_true = y_true.detach()
    y_pred = y_pred.detach()
    var = torch.var(y_true)
    if var < 1e-12:
        return 1.0 if torch.allclose(y_true, y_pred) else 0.0
    return float(1.0 - torch.mean((y_true - y_pred) ** 2) / (var + 1e-12))


def main():
    print(f"Device: {DEVICE}")

    # Load teacher and data
    teacher = load_teacher(PREFIX)            # not strictly needed for training, but nice to have
    x_train, y_train, x_test, y_test = load_data(PREFIX)

    D = x_train.shape[1]
    print(f"Loaded data: D={D}, train={x_train.shape[0]}, test={x_test.shape[0]}")

    # Append a leading 1 to each input for MPS
    def augment_with_one(x: torch.Tensor) -> torch.Tensor:
        """
        x: (N, D) -> (N, D+1) with a leading 1 column.
        """
        ones = torch.ones(x.shape[0], 1, device=x.device, dtype=x.dtype)
        return torch.cat([ones, x], dim=1)

    x_train_aug = augment_with_one(x_train)
    x_test_aug = augment_with_one(x_test)
    D_aug = D + 1

    train_ds = TensorDataset(x_train_aug, y_train)
    test_ds = TensorDataset(x_test_aug, y_test)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)
    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)

    # MPS regressor
    mps = MPS(
        input_dim=D_aug,
        output_dim=1,
        bond_dim=BOND_DIM,
        adaptive_mode=False,
        periodic_bc=False,
    ).to(DEVICE)

    loss_fun = nn.MSELoss()
    optimizer = torch.optim.Adam(mps.parameters(), lr=LEARN_RATE, weight_decay=L2_REG)

    print(
        f"\nTraining MPS on sparse polynomial regression\n"
        f"D_aug={D_aug}, bond_dim={BOND_DIM}, "
        f"N_train={x_train_aug.shape[0]}, N_test={x_test_aug.shape[0]}\n"
    )

    start_time = time.time()

    for epoch in range(1, NUM_EPOCHS + 1):
        # ---- Train ----
        mps.train()
        train_loss = 0.0
        n_seen = 0

        for xb, yb in train_loader:
            xb = xb.to(DEVICE)
            yb = yb.to(DEVICE)

            preds = mps(xb).squeeze(-1)  # [B, 1] -> [B]
            loss = loss_fun(preds, yb)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * xb.size(0)
            n_seen += xb.size(0)

        train_mse = train_loss / max(n_seen, 1)

        # ---- Eval ----
        mps.eval()
        with torch.no_grad():
            ys_list = []
            preds_list = []
            for xb, yb in test_loader:
                xb = xb.to(DEVICE)
                yb = yb.to(DEVICE)
                p = mps(xb).squeeze(-1)
                ys_list.append(yb)
                preds_list.append(p)

            ys = torch.cat(ys_list, dim=0)
            preds = torch.cat(preds_list, dim=0)
            test_mse = float(torch.mean((ys - preds) ** 2))
            test_r2 = r2_score(ys, preds)

        print(f"### Epoch {epoch:03d} ###")
        print(f"Train MSE: {train_mse:.5f}")
        print(f"Test  MSE: {test_mse:.5f} | R2: {test_r2:.4f}")
        print(f"Runtime so far: {int(time.time() - start_time)} sec\n")

    # Save trained MPS
    torch.save(
        {
            "state_dict": mps.state_dict(),
            "D_aug": D_aug,
            "bond_dim": BOND_DIM,
        },
        f"{PREFIX}_mps.pt",
    )
    print(f"Saved trained MPS to {PREFIX}_mps.pt")
    print("Done.")


if __name__ == "__main__":
    main()
